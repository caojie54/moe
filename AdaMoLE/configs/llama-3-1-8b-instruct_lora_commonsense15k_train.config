--model_path=meta-llama/Llama-3.1-8B-Instruct
--data_path=/data/workspace/projects/moe/datasets/commonsense_15k
--peft_type=lora
--lora_rank=16
--target_modules
q_proj
k_proj
v_proj
o_proj
down_proj
--max_length=256
--batch_size=4
--gradient_accumulation_steps=4
--num_train_epochs=5
--learning_rate=1e-4
--lr_scheduler_type=constant_with_warmup
--warmup_steps=200
--weight_decay=0.0
