--model_path=google/gemma-3-12b-it
--data_path=tau/commonsense_qa
--peft_type=adamole
--lora_rank=64
--target_modules
q_proj
k_proj
v_proj
o_proj
down_proj
--num_experts=8
--threshold=0.125
--max_length=256
--batch_size=2
--gradient_accumulation_steps=4
--num_train_epochs=2
--learning_rate=1e-4
--lr_scheduler_type=constant_with_warmup
--warmup_steps=200
--weight_decay=0.0
--aux_loss_coeff=1e-3
